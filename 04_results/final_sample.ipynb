{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPUvD3Q0vCjvHz0/l1gi7Pm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install pytorch-lightning\n","!pip install torchmetrics\n","!pip install rasterio\n","!pip install tim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gr1dNs8ubJ-V","executionInfo":{"status":"ok","timestamp":1765080497628,"user_tz":240,"elapsed":33075,"user":{"displayName":"Daniela Roche","userId":"00518459194697717853"}},"outputId":"f7c0f82d-3df2-4f41-b684-9f547cb60aab"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (2.9.0+cu126)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (4.67.1)\n","Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (6.0.3)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.0)\n","Collecting torchmetrics>0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (25.0)\n","Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (4.15.0)\n","Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.13.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.20.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.5.0)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics>0.7.0->pytorch-lightning) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.22.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.3)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.11)\n","Downloading pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n","Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n","Successfully installed lightning-utilities-0.15.2 pytorch-lightning-2.6.0 torchmetrics-1.8.2\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cu126)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n","Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (1.4.3)\n","Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.4.0)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.11.12)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.1)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio) (0.7.2)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n","Requirement already satisfied: click-plugins in /usr/local/lib/python3.12/dist-packages (from rasterio) (1.1.1.2)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n","Collecting tim\n","  Downloading tim-0.5-py2.py3-none-any.whl.metadata (1.6 kB)\n","Downloading tim-0.5-py2.py3-none-any.whl (4.0 kB)\n","Installing collected packages: tim\n","Successfully installed tim-0.5\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.metrics import r2_score, mean_absolute_error\n","import pytorch_lightning as L\n","import joblib\n","from tqdm import tqdm\n","import rasterio\n","import torchmetrics\n","import timm\n","import torch.nn as nn\n","import os\n","from google.colab import drive\n","import cv2"],"metadata":{"id":"aZyZ0AzvbNF0","executionInfo":{"status":"ok","timestamp":1765080522823,"user_tz":240,"elapsed":25193,"user":{"displayName":"Daniela Roche","userId":"00518459194697717853"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J28lGjgLYDzd","executionInfo":{"status":"ok","timestamp":1765080552017,"user_tz":240,"elapsed":29192,"user":{"displayName":"Daniela Roche","userId":"00518459194697717853"}},"outputId":"9feb8cfb-b250-4575-d161-57fdfc5df777"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["import tifffile\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","img = tifffile.imread('/content/drive/MyDrive/teg_resnet18_arroz/02_dataset/DATASETCONCAT64/images/1920_4307708_3_5.tif')\n","print(img.shape)\n","\n","img_tensor = torch.from_numpy(img).float()  # convertir a tensor float\n","img_tensor = img_tensor.unsqueeze(0)  # añadir dimensión batch si el modelo lo requiere\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Mover tensor al mismo dispositivo que el modelo\n","img_tensor = img_tensor.to(device)\n","\n","#logs_path = \"/content/drive/MyDrive/teg_resnet18_arroz/04_resultados/resnet18_norm_mm_seed_37\"\n","scaler_path = \"/content/drive/MyDrive/teg_resnet18_arroz/02_dataset/DATASETCONCAT64/scaler_mm.pkl\"\n","\n","#csv_file = \"/content/drive/MyDrive/teg_resnet18_arroz/02_dataset/DATASETCONCAT64/sample_100_seed37.csv\"\n","#img_path = \"/content/drive/MyDrive/teg_resnet18_arroz/02_dataset/DATASETCONCAT64/images/1920_4301636_0_0.tif\"\n","#img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n","\n","ckpt_path = \"/content/drive/MyDrive/teg_resnet18_arroz/04_resultados/resnet18_mm/lightning_logs/version_0/checkpoints/epoch=14---val_rmse=0.08---val_loss=0.00.ckpt\"\n","#epoca = \"last\"\n","BATCH_SIZE = 64\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5yDiyhSacbfW","executionInfo":{"status":"ok","timestamp":1765081198869,"user_tz":240,"elapsed":531,"user":{"displayName":"Daniela Roche","userId":"00518459194697717853"}},"outputId":"39302777-e980-464a-d95e-1517a6b154f5"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 64, 10)\n"]}]},{"cell_type":"code","source":["class LightningRegressionTask(L.LightningModule):\n","    def __init__(self, model, model_name, learning_rate=0.001):\n","        super().__init__()\n","        self.save_hyperparameters(ignore=[\"model\"])\n","        self.model = model\n","        #self.criterion = nn.MSELoss() # Cambiar perdida\n","        self.criterion = nn.HuberLoss()\n","        self.learning_rate = learning_rate\n","        self.name = model_name\n","\n","        # Métricas de regresión\n","        self.mse = torchmetrics.MeanSquaredError()\n","        self.rmse = torchmetrics.MeanSquaredError(squared=False)\n","        self.mae = torchmetrics.MeanAbsoluteError()\n","        self.r2 = torchmetrics.R2Score()\n","\n","        self.scaler = joblib.load(scaler_path)\n","\n","        # Diccionarios de logs\n","        self.train_logs = {\"epoch\": [], \"loss\": [], \"mse\": [], \"rmse\": [], \"mae\": [], \"r2\": []}\n","        self.val_logs = {\"epoch\": [], \"loss\": [], \"mse\": [], \"rmse\": [], \"mae\": [], \"r2\": []}\n","        self.test_logs = {\"epoch\": [], \"loss\": [], \"mse\": [], \"rmse\": [], \"mae\": [], \"r2\": []}\n","\n","        self.train_step_loss_logs = {\"step_loss\": []}\n","        self.val_step_loss_logs = {\"step_loss\": []}\n","        self.test_step_loss_logs = {\"step_loss\": []}\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def training_step(self, batch, batch_idx):\n","        images, labels = batch\n","        labels = labels.float().unsqueeze(1) # Asegúrate de que las dimensiones coincidan\n","        preds = self.model(images)\n","        loss = self.criterion(preds, labels)\n","\n","        # Métricas de regresión\n","        mse = self.mse(preds, labels)\n","        rmse = self.rmse(preds, labels)\n","        mae = self.mae(preds, labels)\n","        r2 = self.r2(preds, labels)\n","\n","        # Log de métricas\n","        self.log(\"train_step_loss\", loss, on_step=True, on_epoch=False, prog_bar=True)\n","        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n","        self.log(\"train_mse\", mse, on_step=False, on_epoch=True, prog_bar=True)\n","        self.log(\"train_rmse\", rmse, on_step=False, on_epoch=True, prog_bar=True)\n","        self.log(\"train_mae\", mae, on_step=False, on_epoch=True, prog_bar=True)\n","        self.log(\"train_r2\", r2, on_step=False, on_epoch=True, prog_bar=True)\n","        self.train_step_loss_logs[\"step_loss\"].append(loss.item())\n","        return loss\n","\n","    def on_train_epoch_end(self):\n","        epoch = self.trainer.current_epoch\n","        self.train_logs[\"epoch\"].append(epoch)\n","        self.train_logs[\"loss\"].append(self.trainer.callback_metrics[\"train_loss\"].item())\n","        self.train_logs[\"mse\"].append(self.trainer.callback_metrics[\"train_mse\"].item())\n","        self.train_logs[\"rmse\"].append(self.trainer.callback_metrics[\"train_rmse\"].item())\n","        self.train_logs[\"mae\"].append(self.trainer.callback_metrics[\"train_mae\"].item())\n","        self.train_logs[\"r2\"].append(self.trainer.callback_metrics[\"train_r2\"].item())\n","\n","    def validation_step(self, batch, batch_idx):\n","        images, labels = batch\n","        labels = labels.float().unsqueeze(1)\n","        preds = self.model(images)\n","        loss = self.criterion(preds, labels)\n","\n","        # Métricas de regresión\n","        mse = self.mse(preds, labels)\n","        rmse = self.rmse(preds, labels)\n","        mae = self.mae(preds, labels)\n","        r2 = self.r2(preds, labels)\n","\n","        self.log(\"val_step_loss\", loss, on_step=True, on_epoch=False, prog_bar=True)\n","        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n","        self.log(\"val_mse\", mse, on_step=False, on_epoch=True, prog_bar=True)\n","        self.log(\"val_rmse\", rmse, on_step=False, on_epoch=True, prog_bar=True)\n","        self.log(\"val_mae\", mae, on_step=False, on_epoch=True, prog_bar=True)\n","        self.log(\"val_r2\", r2, on_step=False, on_epoch=True, prog_bar=True)\n","        self.val_step_loss_logs[\"step_loss\"].append(loss.item())\n","        return loss\n","\n","    def on_validation_epoch_end(self):\n","        epoch = self.trainer.current_epoch\n","        self.val_logs[\"epoch\"].append(epoch)\n","        self.val_logs[\"loss\"].append(self.trainer.callback_metrics[\"val_loss\"].item())\n","        self.val_logs[\"mse\"].append(self.trainer.callback_metrics[\"val_mse\"].item())\n","        self.val_logs[\"rmse\"].append(self.trainer.callback_metrics[\"val_rmse\"].item())\n","        self.val_logs[\"mae\"].append(self.trainer.callback_metrics[\"val_mae\"].item())\n","        self.val_logs[\"r2\"].append(self.trainer.callback_metrics[\"val_r2\"].item())\n","\n","    # def on_fit_end(self):\n","    #     # Export logs\n","    #     train_logs_df = pd.DataFrame(self.train_logs)\n","    #     train_step_loss_logs_df = pd.DataFrame(self.train_step_loss_logs)\n","    #     train_logs_df.to_csv(f\"logs-{self.name}_{normalization}_{seed}/training_logs_{self.name}.csv\", index=False)\n","    #     train_step_loss_logs_df.to_csv(f\"logs-{self.name}_{normalization}_{seed}/training_step_loss_logs_{self.name}.csv\", index=False)\n","\n","    #     val_logs_df = pd.DataFrame(self.val_logs)\n","    #     val_step_loss_logs_df = pd.DataFrame(self.val_step_loss_logs)\n","    #     val_logs_df.to_csv(f\"logs-{self.name}_{normalization}_{seed}/validation_logs_{self.name}.csv\", index=False)\n","    #     val_step_loss_logs_df.to_csv(f\"logs-{self.name}_{normalization}_{seed}/validation_step_loss_logs_{self.name}.csv\", index=False)\n","\n","    def test_step(self, batch, batch_idx):\n","        images, labels = batch\n","        labels = labels.float().unsqueeze(1)\n","        preds = self.model(images)\n","        loss = self.criterion(preds, labels)\n","\n","        mse = self.mse(preds, labels)\n","        rmse = self.rmse(preds, labels)\n","        mae = self.mae(preds, labels)\n","        r2 = self.r2(preds, labels)\n","\n","        self.log(\"test_step_loss\", loss, on_step=True, on_epoch=False, prog_bar=True)\n","        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n","        self.log(\"test_mse\", mse, on_step=False, on_epoch=True, prog_bar=True)\n","        self.log(\"test_rmse\", rmse, on_step=False, on_epoch=True, prog_bar=True)\n","        self.log(\"test_mae\", mae, on_step=False, on_epoch=True, prog_bar=True)\n","        self.log(\"test_r2\", r2, on_step=False, on_epoch=True, prog_bar=True)\n","        self.test_step_loss_logs[\"step_loss\"].append(loss.item())\n","        return loss\n","\n","    def on_test_epoch_end(self):\n","        epoch = self.trainer.current_epoch\n","        self.test_logs[\"epoch\"].append(epoch)\n","        self.test_logs[\"loss\"].append(self.trainer.callback_metrics[\"test_loss\"].item())\n","        self.test_logs[\"mse\"].append(self.trainer.callback_metrics[\"test_mse\"].item())\n","        self.test_logs[\"rmse\"].append(self.trainer.callback_metrics[\"test_rmse\"].item())\n","        self.test_logs[\"mae\"].append(self.trainer.callback_metrics[\"test_mae\"].item())\n","        self.test_logs[\"r2\"].append(self.trainer.callback_metrics[\"test_r2\"].item())\n","\n","    # def on_test_end(self):\n","    #     test_logs_df = pd.DataFrame(self.test_logs)\n","    #     test_step_loss_logs_df = pd.DataFrame(self.test_step_loss_logs)\n","    #     test_logs_df.to_csv(f\"logs-{self.name}_{normalization}_{seed}/test_logs_{self.name}.csv\", index=False)\n","    #     test_step_loss_logs_df.to_csv(f\"logs-{self.name}_{normalization}_{seed}/test_step_loss_logs_{self.name}.csv\", index=False)\n","\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n","\n","    def predict_step(self, batch, batch_idx):\n","      x = batch if len(batch) == 1 else batch[0]\n","      y_pred_norm = self(x)\n","      if self.scaler:\n","          y_pred_real = self.scaler.inverse_transform(y_pred_norm.detach().cpu().numpy())\n","          return y_pred_real\n","      return y_pred_norm"],"metadata":{"id":"7W7LQwO2cVkH","executionInfo":{"status":"ok","timestamp":1765080570131,"user_tz":240,"elapsed":2,"user":{"displayName":"Daniela Roche","userId":"00518459194697717853"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["resnet18_model = timm.create_model(\"resnet18\", pretrained=False, in_chans=10, num_classes=1)\n","model = LightningRegressionTask.load_from_checkpoint(ckpt_path, model=resnet18_model, model_name=\"resnet18\")\n","model.to(device)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXEKUPYtcjLW","executionInfo":{"status":"ok","timestamp":1765080586102,"user_tz":240,"elapsed":15971,"user":{"displayName":"Daniela Roche","userId":"00518459194697717853"}},"outputId":"634191f9-cbe1-4b5e-a97e-4470b85dd7a8"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LightningRegressionTask(\n","  (model): ResNet(\n","    (conv1): Conv2d(10, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (act1): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act1): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): ReLU(inplace=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act1): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act1): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act1): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act1): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act1): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act1): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act1): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act2): ReLU(inplace=True)\n","      )\n","    )\n","    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n","    (fc): Linear(in_features=512, out_features=1, bias=True)\n","  )\n","  (criterion): HuberLoss()\n","  (mse): MeanSquaredError()\n","  (rmse): MeanSquaredError()\n","  (mae): MeanAbsoluteError()\n","  (r2): R2Score()\n",")"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["AREATOTAL = 64 * 64 * 100 / 10000"],"metadata":{"id":"6eWl4XcGaxMY","executionInfo":{"status":"ok","timestamp":1765080586106,"user_tz":240,"elapsed":2,"user":{"displayName":"Daniela Roche","userId":"00518459194697717853"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def resize_to_64_64_10(img):\n","    if img.ndim == 2:\n","        img = img[..., np.newaxis]\n","    H, W, C = img.shape\n","    img_resized = cv2.resize(img, (64, 64), interpolation=cv2.INTER_LINEAR)\n","    if C > 10:\n","        img_resized = img_resized[:, :, :10]\n","    elif C < 10:\n","        pad = np.zeros((64, 64, 10 - C), dtype=img_resized.dtype)\n","        img_resized = np.concatenate([img_resized, pad], axis=-1)\n","    return img_resized"],"metadata":{"id":"u0E3n0dAazMO","executionInfo":{"status":"ok","timestamp":1765080586108,"user_tz":240,"elapsed":1,"user":{"displayName":"Daniela Roche","userId":"00518459194697717853"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def compute_roi_percent(img_64_64_10, thresh=0.1):\n","    \"\"\"\n","    Devuelve ROI en porcentaje (0–100), consistente con el entrenamiento.\n","    \"\"\"\n","    mean_img = img_64_64_10.mean(axis=-1)\n","    mean_norm = (mean_img - mean_img.min()) / (np.ptp(mean_img) + 1e-8)  # NumPy 2.0 [web:40][web:42]\n","    roi_mask = mean_norm >= thresh\n","    roi_fraction = roi_mask.sum() / roi_mask.size\n","    roi_percent = roi_fraction * 100.0\n","    return roi_percent, roi_mask.astype(np.uint8)"],"metadata":{"id":"h6ymTo48ocRw","executionInfo":{"status":"ok","timestamp":1765080586110,"user_tz":240,"elapsed":1,"user":{"displayName":"Daniela Roche","userId":"00518459194697717853"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def produccion_a_rendimiento(model, img_tensor, thresh=0.1):\n","    \"\"\"\n","    model: instancia de LightningRegressionTask ya entrenada.\n","    img: imagen (numpy) cualquiera -> se adapta a 64x64x10.\n","    ROI en %, como en el entrenamiento.\n","    \"\"\"\n","    img_norm = resize_to_64_64_10(img).astype(np.float32)\n","\n","    roi_percent, roi_mask = compute_roi_percent(img_norm, thresh=thresh)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        # (H,W,C) -> (1,C,H,W) para PyTorch\n","        inp = torch.tensor(img_norm).unsqueeze(0).permute(0, 3, 1, 2)\n","        inp = inp.to(device) # Move input to the correct device\n","        prod_predicha = model.predict_step(inp, 0)  # ya desnormalizado por el scaler\n","\n","    # prod_predicha puede venir como array; asegúrate de quedarte con el escalar\n","    prod_predicha_val = float(np.array(prod_predicha).reshape(-1)[0])\n","\n","    rendimiento_predicho = prod_predicha_val / (AREATOTAL * (roi_percent / 100))\n","\n","    return rendimiento_predicho, prod_predicha_val, roi_percent, roi_mask"],"metadata":{"id":"FXO_MgnKa3Ee","executionInfo":{"status":"ok","timestamp":1765080586112,"user_tz":240,"elapsed":1,"user":{"displayName":"Daniela Roche","userId":"00518459194697717853"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["rendimiento_predicho, prod_predicha_val, roi_percent, roi_mask = produccion_a_rendimiento(\n","    model, img_tensor, thresh=0.1\n",")\n","\n","print(\"Rendimiento predicho\", rendimiento_predicho)\n","print(\"Producción predicha:\", prod_predicha_val)\n","print(\"Porcentaje ROI\", roi_percent)\n","print(\"Máscara ROI\", roi_mask)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LlOMAsl7a-lG","executionInfo":{"status":"ok","timestamp":1765081203243,"user_tz":240,"elapsed":15,"user":{"displayName":"Daniela Roche","userId":"00518459194697717853"}},"outputId":"07d5c5d2-43ad-48be-e34b-7d79a54884fa"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Rendimiento predicho 7179.476108504843\n","Producción predicha: 59302.47265625\n","Porcentaje ROI 20.166015625\n","Máscara ROI [[0 0 0 ... 1 1 1]\n"," [0 0 0 ... 1 1 1]\n"," [0 0 0 ... 1 1 1]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n"]}]}]}